{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ‚õµ Resume Analyzer & Job Finder with Google ADK, Nebius, Mistral & Linkup\n",
        "\n",
        "This notebook demonstrates how to use the Google Agent Development Kit (ADK) to create a multi-agent system that:\n",
        "\n",
        "- üê≥ Extracts resume content from uploaded PDFs using Mistral OCR  \n",
        "- üöÄ Prepares tailored job search queries  \n",
        "- üîé Uses Linkup API to search Hacker News and Wellfound  \n",
        "- üßæ Compiles and formats relevant job listings\n",
        "\n",
        "Powered by: `Qwen3-14B` via [Nebius AI Studio](https://studio.nebius.ai)"
      ],
      "metadata": {
        "id": "5CFY75hEZ111"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üõ†Ô∏è Step 1: Install Required Packages\n",
        "\n",
        "!pip install -q google-adk mistralai python-dotenv litellm linkup-sdk"
      ],
      "metadata": {
        "id": "A5DFOneHaEhl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üß± Step 2: Import Required Libraries\n",
        "\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "from google.colab import files\n",
        "\n",
        "# Mistral\n",
        "from mistralai import Mistral\n",
        "from mistralai.client import MistralClient\n",
        "\n",
        "# Google ADK\n",
        "from google.adk.agents.llm_agent import LlmAgent\n",
        "from google.adk.agents.sequential_agent import SequentialAgent\n",
        "from google.adk.models.lite_llm import LiteLlm\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.genai import types\n",
        "\n",
        "# Linkup\n",
        "from linkup import LinkupClient\n"
      ],
      "metadata": {
        "id": "O8BQB81KaKEM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîê Setting Up API Keys"
      ],
      "metadata": {
        "id": "Bgre-R57aUkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Set up API Key\n",
        "\n",
        "os.environ[\"NEBIUS_API_BASE\"] = \"https://api.studio.nebius.ai/v1\"\n",
        "os.environ[\"NEBIUS_API_KEY\"] = \"your-api-key\"\n",
        "os.environ[\"MISTRAL_API_KEY\"] = \"your-api-key\"\n",
        "os.environ[\"LINKUP_API_KEY\"] = \"your-api-key\""
      ],
      "metadata": {
        "id": "u7dx9MOsaMy0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Qwen3 Setup"
      ],
      "metadata": {
        "id": "LbcshwVN8qX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define Qwen3 model from Nebius AI for ADK compatibility using LiteLLM\n",
        "\n",
        "nebius_llm = LiteLlm(\n",
        "    model=\"openai/Qwen/Qwen3-14B\",\n",
        "    api_base=os.getenv(\"NEBIUS_API_BASE\"),\n",
        "    api_key=os.getenv(\"NEBIUS_API_KEY\")\n",
        ")"
      ],
      "metadata": {
        "id": "6cDF3qcwajlV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üî≠ Define OCR and Search Tool (Mistral OCR + Linkup)"
      ],
      "metadata": {
        "id": "VRDGmoKja2l7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Define OCR Tool that uses Mistral OCR model\n",
        "\n",
        "def run_mistral_ocr(file_path: str) -> dict:\n",
        "    try:\n",
        "        client = Mistral(api_key=os.getenv(\"MISTRAL_API_KEY\"))\n",
        "\n",
        "        # Upload PDF to Mistral\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            uploaded_pdf = client.files.upload(\n",
        "                file={\"file_name\": os.path.basename(file_path), \"content\": f},\n",
        "                purpose=\"ocr\"\n",
        "            )\n",
        "\n",
        "        # Get signed URL\n",
        "        signed_url = client.files.get_signed_url(file_id=uploaded_pdf.id)\n",
        "\n",
        "        # Process OCR\n",
        "        ocr_response = client.ocr.process(\n",
        "            model=\"mistral-ocr-latest\",\n",
        "            document={\"type\": \"document_url\", \"document_url\": signed_url.url},\n",
        "            include_image_base64=False  # or True if needed\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"type\": \"ocr_result\",\n",
        "            \"text\": ocr_response.text if hasattr(ocr_response, \"text\") else str(ocr_response)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"type\": \"error\", \"error\": str(e)}"
      ],
      "metadata": {
        "id": "2l7KQtOtaymi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Define Linkup search tool to find jobs from Ycombinator and Wellfound\n",
        "\n",
        "def run_linkup_deepsearch(linkup_query: str) -> dict:\n",
        "    try:\n",
        "        client = LinkupClient(api_key=os.getenv(\"LINKUP_API_KEY\"))\n",
        "\n",
        "        # Incorporate site restrictions\n",
        "        query = f\"\"\"\n",
        "        <guidance>\n",
        "        <restrictions>\n",
        "          Use only the sources listed here:\n",
        "            - ycombinator.com\n",
        "            - wellfound.com\n",
        "        </restrictions>\n",
        "        </guidance>\n",
        "\n",
        "        {linkup_query}\n",
        "        \"\"\"\n",
        "\n",
        "        search_response = client.search(\n",
        "            query=query,\n",
        "            depth=\"deep\",\n",
        "            output_type=\"searchResults\"\n",
        "        )\n",
        "        return {\n",
        "            \"type\": \"linkup_search_result\",\n",
        "            \"results\": search_response\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"type\": \"error\", \"error\": str(e)}"
      ],
      "metadata": {
        "id": "nxoi-468bF4y"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ü§ñ Setting up AI Agents (4 Sub-agents)"
      ],
      "metadata": {
        "id": "Lh5W0gVV1fTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step7: Define Agents\n",
        "\n",
        "# AGENT-1 to read Resume\n",
        "\n",
        "ocr_agent = LlmAgent(\n",
        "    name=\"MistralOCRAgent\",\n",
        "    model=nebius_llm,\n",
        "    description=\"Extracts text from a PDF using Mistral OCR.\",\n",
        "    instruction=(\n",
        "        \"Use the `run_mistral_ocr` tool to extract text from a given PDF file path. \"\n",
        "        \"Only return the extracted plain text content. Do not include any explanation or commentary. \"\n",
        "        \"Prefix your response with (üê≥ OCRAgent:).\"\n",
        "    ),\n",
        "    tools=[run_mistral_ocr],\n",
        "    output_key=\"ocr_output\"\n",
        ")"
      ],
      "metadata": {
        "id": "87YFa-Vg1l2r"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AGENT-2 to prepare search queries based on resume content for Linkup search\n",
        "\n",
        "query_prep_agent = LlmAgent(\n",
        "    name=\"QueryPrepAgent\",\n",
        "    model=nebius_llm,\n",
        "    description=\"Prepares search queries based on OCR output to find relevant job postings.\",\n",
        "    instruction=(\n",
        "        \"Analyze the resume content from {ocr_output} and generate up to 5 precise search queries. \"\n",
        "        \"Each query should focus on specific job roles, skills, experiences or technologies mentioned. \"\n",
        "        \"Target platforms: Hacker News jobs and Wellfound (AngelList). \"\n",
        "        \"Format each query as a bullet point. Prefix your response with (üöÄ QueryPrepAgent:).\"\n",
        "    ),\n",
        "    tools=[],\n",
        "    output_key=\"linkup_query\"\n",
        ")"
      ],
      "metadata": {
        "id": "AmGSTy8a17fe"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AGENT-3 to use Linkup search tool to perform job search\n",
        "\n",
        "linkup_search_agent = LlmAgent(\n",
        "    name=\"LinkupSearchAgent\",\n",
        "    model=nebius_llm,\n",
        "    description=\"Searches for jobs using the Linkup API with provided queries.\",\n",
        "    instruction=(\n",
        "        \"Using the queries provided in {linkup_query}, call the `run_linkup_deepsearch` tool to search for job postings. \"\n",
        "        \"Limit the results to jobs from Hacker News and Wellfound.\"\n",
        "        \"Only pick most recent and latest job links. Prefix your response with (üîé LinkupSearch:).\"\n",
        "    ),\n",
        "    tools=[run_linkup_deepsearch],\n",
        "    output_key=\"linkup_search_result\"\n",
        ")"
      ],
      "metadata": {
        "id": "8HUHNTc62P4q"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AGENT-4 to prepare final list of suitable jobs based on uploaded resume with other infos\n",
        "\n",
        "job_filter_agent = LlmAgent(\n",
        "    name=\"JobFilterAgent\",\n",
        "    model=nebius_llm,\n",
        "    description=\"Compiles and formats relevant job listings based on resume and search results.\",\n",
        "    instruction=(\n",
        "        \"Using the resume content from {ocr_output} and the search results from {linkup_search_result}, compile a list of relevant job postings. \"\n",
        "        \"For each job, include:\\n- Job title\\n- Company name\\n- Application link (if available)\\n- Source (e.g., Hacker News, Wellfound). \"\n",
        "        \"Present the results in a clear, easy-to-read format (e.g., numbered list). \"\n",
        "        \"Make a priority order based on experince needed in jobs with higher chances to get selected. \"\n",
        "        \"Prefix your response with (üßæ JobFilterAgent:).\"\n",
        "    ),\n",
        "    tools=[],\n",
        "    output_key=\"job_filter\"\n",
        ")"
      ],
      "metadata": {
        "id": "Diyy5aY82sIP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéÆ Pipeline & Execution (Host Agent)"
      ],
      "metadata": {
        "id": "_JRXpBMy3OOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Combine into pipeline\n",
        "\n",
        "job_finder = SequentialAgent(\n",
        "    name=\"OCRSequentialAgent\",\n",
        "    sub_agents=[ocr_agent, query_prep_agent, linkup_search_agent, job_filter_agent] # subagents\n",
        ")\n",
        "\n",
        "# Step 9: Setup session and runner\n",
        "APP_NAME = \"ai_ocr_pipeline\"\n",
        "USER_ID = \"colab_user\"\n",
        "SESSION_ID = \"ocr_test_session\"\n",
        "\n",
        "session_service = InMemorySessionService()\n",
        "session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n",
        "runner = Runner(agent=job_finder, app_name=APP_NAME, session_service=session_service)"
      ],
      "metadata": {
        "id": "xaIHe0pe3YPG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Run the whole Agent flow to get results"
      ],
      "metadata": {
        "id": "OnZLSZwT3wdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: # Define the main function to run the AI analysis\n",
        "\n",
        "def run_ai_analysis():\n",
        "    uploaded = files.upload()\n",
        "    file_path = list(uploaded.keys())[0]  # Get the uploaded file's path\n",
        "\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=file_path)])\n",
        "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
        "\n",
        "    for event in events:\n",
        "        if event.is_final_response():\n",
        "            # Use Markdown for formatting\n",
        "            formatted_output = f\"## Let's find perfect Job for you:\\n\\n{event.content.parts[0].text}\"\n",
        "            display(Markdown(formatted_output))\n",
        "\n",
        "\n",
        "run_ai_analysis() # Execute the AI analysis sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kKh6uHyF37ep",
        "outputId": "6e32bb94-7c7f-4163-9d75-a3b61c62d3fd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a667e7b8-06cc-4058-93ec-8c9edc0fca3e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a667e7b8-06cc-4058-93ec-8c9edc0fca3e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving SiddharthCV.pdf to SiddharthCV (2).pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Let's find perfect Job for you:\n\n<think>\nOkay, the user asked me to extract text from the PDF \"SiddharthCV (2).pdf\". I used the run_mistral_ocr tool for that. The response came back with the OCR result, which is the text content of the PDF. Now, I need to present this extracted text as the answer.\n\nFirst, I'll check if the OCR result is correctly formatted. The text seems to be in markdown, which is fine. The user wanted plain text, so maybe I should just output it as is without any changes. Let me make sure there are no errors in the extracted text. The content includes sections like Education, Skill Set, Projects, Achievements, and Technical Skills. It looks comprehensive.\n\nI should confirm that the tool response doesn't have any additional information beyond the text. The JSON structure has a \"text\" field which contains the markdown content. The user specified to only return the extracted plain text, so I should avoid adding any explanations or formatting. Just the raw text from the OCR result. \n\nWait, the user mentioned \"plain text content\", but the extracted text is in markdown. However, the instruction says to return the extracted content as is. Since the OCR tool returned markdown, I should present it as such. The user might be expecting markdown or just plain text. But since the tool's output is markdown, I'll go with that unless told otherwise. \n\nNo, the user said \"plain text\", so maybe I should remove markdown formatting. But the initial instruction says \"Only return the extracted plain text content. Do not include any explanation or commentary.\" The OCR result is the text extracted from the PDF, which might include markdown. However, the user might want it without markdown. Hmm, but the tool's output is in markdown. Should I process it further? The user hasn't specified, so perhaps just return the OCR result as it is, since that's what the tool provided. \n\nThe user also said to prefix the response with (üê≥ OCRAgent:). So I'll add that prefix followed by the extracted text. Let me make sure there are no additional characters or formatting. Alright, I'll structure the answer with the prefix and the OCR text.\n</think>\n\n(üê≥ OCRAgent: # SIDDHARTH MISHRA \n\n## Education\n\nSIES Graduate School of Technology\nBachelor of Engineering in Artificial Intelligence and Data Science - 8.6/10\nShri T.P Bhatia College of Science\nHigher Secondary Education - 91.16%\nDew\nN\nNerul, Navi Mumbai\n\nJuly 2019 - April 2021\nMumbai, Maharashtra\n\n## Skill Set\n\n- Neural Networks\n- Computer Vision\n- NLP\n- GenAI\n- LLMs\n- Deep Learning\n- Machine Learning\n- Power BI\n\n\n## Projects\n\nDemand Forecasting Model | Time Series Forecasting, NBeats, Generative AI (1)\n\n- Predicted sales trends, reducing overstocking and cutting excess costs by $\\mathbf{1 5 \\%}$, optimizing supply chains.\n- Provided 90-day forecasts, helping businesses plan inventory and purchasing efficiently, minimizing last-minute orders.\n- Built an Q&A Bot to simplify sales trend analysis and insights, making real-time decision-making easier.\n- Enhanced forecast accuracy using deep learning, outperforming traditional statistical models.\n\n\nTextract | PDF Processing, Automation, Computer Vision (1)\n\n- Automated PDF data extraction, reducing manual work by $\\mathbf{7 5 \\%}$ and eliminating human errors in processing.\n- Streamlined compliance, documentation, and data entry for businesses, saving hours of labor.\n- Enabled quick keyword searches inside PDFs, making information retrieval as easy as a Google search.\n- Integrated Generative AI to summarize extracted content, providing quick document insights.\n\n\nCancero | CNN, Medical Imaging, Gemini API, Healthcare Tech (1)\n\n- Achieved $\\mathbf{9 2} \\%$ accuracy in cancer detection from MRI and CT scans, improving early diagnosis rates.\n- Reduced screening costs by prioritizing high-risk patients efficiently, optimizing resource allocation.\n- Expanded AI-powered diagnostics to rural and underserved clinics, increasing accessibility to expert-level analysis.\n- Integrated ChatBot to provide explanations for AI-generated diagnoses, assisting doctors in decision-making.\n\n\n## Achievements/Extra Curricular\n\n## Level SuperMind Hackathon 2025 | National Finalist (1)\n\n- Finalist in the Level Supermind Hackathon 2025, a national level competition in collaboration with BeerBiceps, Hitesh Choudhary, AWS, LangFlow, and DataStax. Invited to the Level office in Mumbai to solve a real-world challenge in a 24-hour overnight hackathon.\n\n\n## Google GenAI Exchange Hackathon 2024 | Top 5 Team (1)\n\n- Finalist among the top 5 teams in the Glance Problem Track, out of over 38,000 registrations and 3,300 teams formed across Asia. Invited to Google's Gurgaon office for a special Demo Day to present our solution to industry leaders and experts.\n\n\nSmart India Hackathon 2023 | All-India Rank 7\n\n- Ranked 7th all-India and waitlisted for a computer vision problem statement in SIH 2023. Cleared the internal hackathon and was the only team from the college to reach the official first round of SIH 2023.\n\n\nFr. Conceicao Rodrigues Memorial Debate | National-Level Participant\n\n- Represented the college in the 25th Edition of the Fr. Conceicao Rodrigues Memorial Debate Competition as part of a team.\n\n\n## Technical Skills\n\nLanguages: Python, C++, SQL\nDeveloper Tools: Streamlit, AWS, Hugging Face, GenAI, YOLO, GCP, React\nTechnologies/Frameworks: LangFlow, DataStax, LangChain, Flask, LLMs)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Let's find perfect Job for you:\n\n<think>\nOkay, the user provided the resume content extracted from the PDF, and now they want me to generate up to 5 precise search queries for job postings on Hacker News and Wellfound (AngelList). The queries should focus on the specific job roles, skills, experiences, or technologies mentioned in the resume.\n\nFirst, I need to parse the resume content thoroughly. Let's look at the key sections:\n\n**Education**: Bachelor's in AI and Data Science, Higher Secondary with 91.16%.\n\n**Skill Set**: Neural Networks, Computer Vision, NLP, GenAI, LLMs, Deep Learning, Machine Learning, Power BI.\n\n**Projects**:\n1. Demand Forecasting Model using Time Series, NBeats, Generative AI. Achieved 15% cost reduction.\n2. Textract for PDF automation, reducing manual work by 75%.\n3. Cancero for cancer detection with 92% accuracy using CNN and Gemini API.\n\n**Achievements**:\n- National Finalist in Level SuperMind Hackathon 2025.\n- Top 5 in Google GenAI Exchange Hackathon 2024.\n- All-India Rank 7 in Smart India Hackathon 2023.\n- National-level debate participant.\n\n**Technical Skills**: Python, C++, SQL, Streamlit, AWS, Hugging Face, GenAI, YOLO, GCP, React, LangFlow, DataStax, LangChain, Flask, LLMs.\n\nNow, identify the key terms and areas to focus on for job searches. The candidate has strong experience in AI, machine learning, computer vision, Generative AI, and has participated in notable hackathons. They also have skills in cloud platforms like AWS and GCP, and tools like Streamlit, React, etc.\n\nPossible job roles could be Machine Learning Engineer, AI Researcher, Data Scientist, Computer Vision Engineer, GenAI Developer, etc. The projects and achievements highlight expertise in predictive modeling, automation, healthcare tech, and competition success.\n\nI need to create specific search queries that target these areas. Let's ensure each query is unique and covers different aspects: technical skills, project domains, hackathon experience, specific technologies, and roles.\n\nAvoiding repetition, I can phrase queries around \"Machine Learning Engineer with Generative AI experience,\" \"Computer Vision and Medical Imaging projects,\" \"Hackathon finalists in AI/ML,\" \"PDF automation and data extraction,\" and \"Healthcare tech solutions using AI.\"\n\nMake sure to use relevant keywords from the resume and tailor each query to highlight different strengths. Also, check for any specific technologies or frameworks mentioned, like YOLO, LangChain, etc., to include in the queries.\n</think>\n\n(üöÄ QueryPrepAgent:  \n- \"Machine Learning Engineer with Generative AI and computer vision experience (NLP, LLMs, CNN)\"  \n- \"AI/ML Developer specializing in healthcare diagnostics (cancer detection, medical imaging, Gemini API)\"  \n- \"Data Scientist with time series forecasting expertise (NBeats, demand forecasting, supply chain optimization)\"  \n- \"PDF automation engineer with Generative AI integration (Textract, YOLO, Streamlit, AWS/GCP)\"  \n- \"Hackathon finalist in AI/ML (Level SuperMind, Google GenAI Exchange, Smart India Hackathon)\"  \n)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Let's find perfect Job for you:\n\n<think>\nOkay, let me try to figure out what the user needs here. They provided a resume and wanted job search queries for Hacker News and Wellfound. The assistant generated five queries and then ran the search tool for each. Now, there are several tool responses with job listings. The user probably wants these results compiled into a concise list of relevant job opportunities.\n\nFirst, I need to parse through the tool responses. There are multiple results from Wellfound and Hacker News. The key is to extract the most relevant job postings that match the resume's skills and experiences. The resume mentions Machine Learning, Generative AI, Computer Vision, Healthcare Tech, and hackathon experience.\n\nLooking at the results, there are positions like Machine Learning Engineer (Generative AI), AI/ML Developer in healthcare, Data Scientist for time series forecasting, Generative AI Engineer roles, and mentions of hackathons. I should highlight these, especially those that mention specific technologies the candidate knows, like YOLO, TensorFlow, PyTorch, AWS, GCP, etc.\n\nAlso, the candidate has projects in PDF automation with Textract and healthcare diagnostics with Gemini API, so jobs related to those areas should be prioritized. Hackathon experience is mentioned in the resume, so any job that values hackathon participation or competition experience would be good.\n\nI need to ensure the final answer is a list of job links with brief descriptions, focusing on the most relevant matches. Make sure to mention the company names, job titles, and key requirements or highlights from the job postings that align with the resume. Avoid less relevant or duplicate entries. Check the links to ensure they are valid and from the specified platforms (Hacker News and Wellfound).\n</think>\n\n(‚úÖ LinkupSearch:  \n1. **Machine Learning Engineer (Generative AI)** @ [wellfound.com](https://wellfound.com/jobs/3175985-machine-learning-engineer-generative-ai)  \n   - Focus: Generative AI, NLP, LLMs, CNN | Requires 2‚Äì3 years of AI/ML experience.  \n\n2. **Healthcare AI Developer** @ [wellfound.com](https://wellfound.com/jobs/3246792-generative-ai-nlp-engineer-llm)  \n   - Focus: Medical imaging, cancer detection, Gemini API | Requires NLP/LLM expertise.  \n\n3. **Data Scientist (Time Series Forecasting)** @ [wellfound.com](https://wellfound.com/jobs/2890179-data-scientist-demand-or-time-series-forecasting)  \n   - Focus: Demand forecasting, NBeats, supply chain optimization | Requires 1‚Äì4 years of DS experience.  \n\n4. **PDF Automation Engineer** @ [wellfound.com](https://wellfound.com/jobs/3261057-generative-ai-engineer)  \n   - Focus: Generative AI, Textract, Python, NLP | Requires automation/ML integration skills.  \n\n5. **Hackathon-Focused AI Engineer** @ [yc.com](https://www.ycombinator.com/companies/skylink/jobs/8qQ9NQ9-founding-ml-nlp-engineer)  \n   - Focus: NLP, LLMs, chatbot development | Prior hackathon experience (e.g., Smart India Hackathon) is a plus.  \n\n6. **Computer Vision Engineer** @ [wellfound.com](https://wellfound.com/jobs/3252840-sr-machine-learning-engineer-computer-vision)  \n   - Focus: CNN, YOLO, medical imaging | Requires 5+ years in computer vision at scale.  \n\n7. **LLM Research Scientist** @ [wellfound.com](https://wellfound.com/jobs/3075768-ai-ml-research-scientist-engineer-must-have-experience-in-generative-ai-llm-related-products)  \n   - Focus: Generative AI, LLM alignment, enterprise AI | Requires PhD/MSc in CS or related field.  \n\n8. **Healthcare AI Startup Roles** @ [wellfound.com](https://wellfound.com/company/stackai)  \n   - Focus: Generative AI for healthcare workflows | Requires experience with LLMs and healthcare data.  \n\n9. **Y Combinator AI Startups** @ [yc.com](https://www.ycombinator.com/companies/eloquent-ai/jobs/SSxWDim-ai-engineer-multimodal-llms)  \n   - Focus: Multimodal LLMs, RAG, reinforcement learning | Prior hackathon success (e.g., Level SuperMind) aligns well.  \n\n10. **AI/ML Engineer (Remote)** @ [wellfound.com](https://wellfound.com/jobs/3244410-ai-ml-developer)  \n    - Focus: Python, AWS, ML deployment | Requires 2+ years in AI/ML development.  \n)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Let's find perfect Job for you:\n\n<think>\nOkay, let's tackle this. The user has a resume with a strong background in AI, machine learning, computer vision, and Generative AI. They've also participated in several hackathons, which is a plus. The job search results from Wellfound and Hacker News have been compiled, and now I need to prioritize these opportunities based on relevance to the resume content. \n\nFirst, the key areas from the resume are: Machine Learning, Generative AI, Computer Vision, Healthcare Tech, and hackathon experience. Looking at the job listings, the positions that mention Generative AI, NLP, LLMs, and computer vision seem most relevant. The healthcare tech roles, especially those involving cancer detection or medical imaging, align with the Cancero project in the resume. \n\nHackathon experience is highlighted in the resume, so any job that mentions hackathon participation or competition success would be a good fit. For example, the Y Combinator startups that are focused on AI and have a history of hackathon involvement might be a good match.\n\nI should also check for roles that require specific technologies the candidate knows, like YOLO, TensorFlow, PyTorch, AWS, GCP, etc. Jobs that mention these tools or similar ones would be more relevant. The Data Scientist role for time series forecasting matches the Demand Forecasting Model project, so that's important.\n\nI need to make sure not to include duplicate entries or less relevant jobs. For instance, some entries might be for general AI roles without specific focus areas, which might not be as aligned with the candidate's skills. Also, verifying the links to ensure they're valid and from the specified platforms is important.\n\nPrioritizing based on the resume's strengths, the top positions would be those in Generative AI, healthcare AI, computer vision, and those that value hackathon experience. I'll list these first, followed by other relevant roles that still match some aspects of the resume but might not be as closely aligned. Including a brief description for each job to highlight why it's a good fit would help the user understand the relevance.\n</think>\n\n(üßæ JobFilterAgent:  \n### üéØ Top 5 Relevant Job Matches Based on Resume & Search Results:  \n\n1. **Machine Learning Engineer (Generative AI) @ [wellfound.com](https://wellfound.com/jobs/3175985-machine-learning-engineer-generative-ai)**  \n   - **Why**: Matches Generative AI, LLMs, NLP, and CNN expertise. Aligns with projects like **Demand Forecasting Model** and **Cancero (cancer detection)**.  \n   - **Skills Required**: Python, TensorFlow/PyTorch, prompt engineering.  \n\n2. **Healthcare AI Developer @ [wellfound.com](https://wellfound.com/jobs/3246792-generative-ai-nlp-engineer-llm)**  \n   - **Why**: Focus on medical imaging and cancer detection (matches **Cancero project**). Uses **Gemini API** (similar to resume‚Äôs healthcare tech experience).  \n   - **Skills Required**: NLP, LLMs, medical AI, Python.  \n\n3. **Hackathon-Focused AI Engineer @ [yc.com](https://www.ycombinator.com/companies/skylink/jobs/8qQ9NQ9-founding-ml-nlp-engineer)**  \n   - **Why**: Prior hackathon success (Smart India Hackathon, Level SuperMind) is a key differentiator. Role emphasizes **NLP and LLMs** for chatbot development.  \n   - **Skills Required**: NLP, LLMs, chatbot design, Python.  \n\n4. **Computer Vision Engineer @ [wellfound.com](https://wellfound.com/jobs/3252840-sr-machine-learning-engineer-computer-vision)**  \n   - **Why**: Matches **YOLO, CNN, CNN-based medical imaging** (Cancero). Requires 5+ years in computer vision at scale.  \n   - **Skills Required**: CNN, YOLO, Python, medical imaging.  \n\n5. **Data Scientist (Time Series Forecasting) @ [wellfound.com](https://wellfound.com/jobs/2890179-data-scientist-demand-or-time-series-forecasting)**  \n   - **Why**: Aligns with **Demand Forecasting Model** using NBeats and supply chain optimization.  \n   - **Skills Required**: Time series, Python, machine learning.  \n\n---\n\n### üìå Additional Opportunities (Secondary Matches):  \n- **LLM Research Scientist @ [wellfound.com](https://wellfound.com/jobs/3075768-ai-ml-research-scientist-engineer-must-have-experience-in-generative-ai-llm-related-products)**  \n  - PhD/MS in AI, focus on LLM alignment. Matches **GenAI and NLP** strengths.  \n\n- **PDF Automation Engineer @ [wellfound.com](https://wellfound.com/jobs/3261057-generative-ai-engineer)**  \n  - Involves **Textract and Generative AI** (similar to resume‚Äôs PDF automation project).  \n\n- **Y Combinator AI Startups (Multimodal LLMs) @ [yc.com](https://www.ycombinator.com/companies/eloquent-ai/jobs/SSxWDim-ai-engineer-multimodal-llms)**  \n  - Requires **RAG, LLMs, and multimodal expertise**. Fits hackathon innovation background.  \n\n- **Healthcare AI Startup @ [wellfound.com](https://wellfound.com/company/stackai)**  \n  - Focus on **LLMs for healthcare applications**. Matches Cancero and hackathon experience.  \n\n- **AI/ML Engineer (Remote) @ [wellfound.com](https://wellfound.com/jobs/3244410-ai-ml-developer)**  \n  - Python, AWS, and ML deployment focus. Good fit for foundational skills.  \n\n---\n\n### üìå Notes:  \n- **Hackathon experience** (Level SuperMind, Google GenAI Exchange) is a **key differentiator** for roles like SkyLink and Y Combinator startups.  \n- **Computer Vision and Healthcare AI** roles (items 4 and 2) are **highly aligned** with the **Cancero project** and medical imaging expertise.  \n- **Time Series Forecasting** (item 5) directly matches the **Demand Forecasting Model** project.  \n\nLet me know if you‚Äôd like to refine this list further!"
          },
          "metadata": {}
        }
      ]
    }
  ]
}